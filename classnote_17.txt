Snowflake Realtime Training 
								        Session-17
								--------------------------
								          Snow Pipe 
								
								https://youtu.be/25khzW6hw4E
								
								Data loading 
								
								Bulk loading -->  AWS bucket 
								                  IAM 
												  Storage integration 
												  Copy command to load the data (Manual)
								
								
								continious loading 
								
							               --> AWS bucket  
										       IAM 
											   Storage integration 
											   Create pipe (Copy command) 
											   
		AWS -->  5 mins  employee details 	

                run -->  copy command    1 hr 
                       12 files are finding data is not synch 

                       24 hrs --> copy commands 
					   
					   
 s3:   s3://snow-emp-vitech-data/csv/
 
 role : ARN == arn:aws:iam::024848483653:role/snow-pipe-role
 
 uer :  arn:aws:iam::211125613752:user/externalstages/ci4zx60000
 
 ex: RW49251_SFCRole=2_TiA3ageMrvgHze/RUcO1XAsRwh4=
 
 
 --------------------
 Setup event trigger for pipe
  ------------------------------------

	Amazon S3--> bucket --> properties -->  Event Notifications --> Create event notification

	Event Name -snowflake notification as name
	add prefix - csv/

	Event type - All or based on your requirement

	Destination : Select (SQS Queue) --> Enter SQS Queue ARN
	selected  Notification ARN need to configure here
	Save changes


    --------------------------------------------------------
	Goto Objects and test snowpipe
	Add the files and see how values are inserted
	
	run the below SQL --> It will take 30 to 60 sec to run pipe
	SELECT * FROM OUR_FIRST_DB.PUBLIC.employees

	ALTER pipe employee_pipe refresh;
	
---------------------------------------------------
// Create storage integration object

create or replace storage integration s3_int_pipe
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = S3
  ENABLED = TRUE 
  STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::024848483653:role/snow-pipe-role'
  STORAGE_ALLOWED_LOCATIONS = ('s3://snow-emp-vitech-data/csv/')
   COMMENT = 'This is to practice pipe concept' 
   
   
// See storage integration properties to fetch external_id so we can update it in S3
DESC integration s3_int_pipe;




// Create table first
CREATE OR REPLACE TABLE OUR_FIRST_DB.PUBLIC.employees (
  id INT,
  first_name STRING,
  last_name STRING,
  email STRING,
  location STRING,
  department STRING
  )
    

// Create file format object
CREATE OR REPLACE file format MANAGE_DB.file_formats.csv_fileformat
    type = csv
    field_delimiter = ','
    skip_header = 1
    null_if = ('NULL','null')
    empty_field_as_null = TRUE;
    
    
 // Create stage object with integration object & file format object
CREATE OR REPLACE stage MANAGE_DB.external_stages.csv_folder
    URL = ' s3://snow-emp-vitech-data/csv/'
    STORAGE_INTEGRATION = s3_int_pipe
    FILE_FORMAT = MANAGE_DB.file_formats.csv_fileformat
   

 // Create stage object with integration object & file format object
LIST @MANAGE_DB.external_stages.csv_folder  


// Create schema to keep things organized
CREATE OR REPLACE SCHEMA MANAGE_DB.pipes

// Define pipe
CREATE OR REPLACE pipe MANAGE_DB.pipes.employee_pipe
auto_ingest = TRUE
AS
COPY INTO OUR_FIRST_DB.PUBLIC.employees
FROM @MANAGE_DB.external_stages.csv_folder  

// Describe pipe
DESC pipe employee_pipe
    
SELECT * FROM OUR_FIRST_DB.PUBLIC.employees    

ALTER pipe employee_pipe refresh;


----------------------------------------------



-- Manage pipes -- 

DESC pipe MANAGE_DB.pipes.employee_pipe;

SHOW PIPES;

SHOW PIPES like '%employee%'

SHOW PIPES in database MANAGE_DB

SHOW PIPES in schema MANAGE_DB.pipes

SHOW PIPES like '%employee%' in Database MANAGE_DB


-- Changing pipe (alter stage or file format) --


// Pause pipe
ALTER PIPE MANAGE_DB.pipes.employee_pipe SET PIPE_EXECUTION_PAUSED = true

ALTER PIPE MANAGE_DB.pipes.employee_pipe SET PIPE_EXECUTION_PAUSED = false
 
// Verify pipe is paused and has pendingFileCount 0 
SELECT SYSTEM$PIPE_STATUS('MANAGE_DB.pipes.employee_pipe') 
 
 // Recreate the pipe to change the COPY statement in the definition
CREATE OR REPLACE pipe MANAGE_DB.pipes.employee_pipe
auto_ingest = TRUE
AS
COPY INTO OUR_FIRST_DB.PUBLIC.employees2
FROM @MANAGE_DB.external_stages.csv_folder  

ALTER PIPE  MANAGE_DB.pipes.employee_pipe refresh



// Resume pipe
ALTER PIPE MANAGE_DB.pipes.employee_pipe SET PIPE_EXECUTION_PAUSED = false

// Verify pipe is running again
SELECT SYSTEM$PIPE_STATUS('MANAGE_DB.pipes.employee_pipe') 

